<img src="https://historia.nationalgeographic.com.es/medio/2023/06/20/the-steamship-titanic-rmg-bhc3667_00000000_9b5bd117_230620084252_1200x630.jpg">

## Tabla de contenidos

1. [Descripci贸n del Proyecto](#descripci贸n-del-proyecto-clipboard)
2. [Evaluaci贸n](#evaluaci贸n-chart_with_upwards_trend)
3. [Herramientas Utilizadas](#herramientas-utilizadas-wrench)
4. [Estructura del Proyecto](#estructura-del-proyecto-open_file_folder)
5. [C贸mo usar este proyecto](#c贸mo-usar-este-proyecto-question)
6. [Contenido del Jupyter notebook](#contenido-del-jupyter-notebook-page_facing_up)
7. [Modelos Utilizados](#modelos-utilizados-computer)
8. [Resultados](#resultados-bar_chart)


# Recomendador Anime 

### Descripci贸n del Proyecto :clipboard:
Este proyecto utiliza el conjunto de datos disponible en Kaggle (https://www.kaggle.com/competitions/titanic) para realizar un an谩lisis de datos utilizando Python. El objetivo principal es usar Machine Learning para crear un modelo que prediga qu茅 pasajeros sobrevivieron al hundimiento del Titanic.

### Evaluaci贸n :chart_with_upwards_trend:
La m茅trica que se busca mejorar es el accuracy (exactitud). Esta m茅trica se utiliza para evaluar la precisi贸n de un modelo de clasificaci贸n. Se calcula dividiendo el n煤mero de predicciones correctas (clasificaciones correctas) entre el n煤mero total de predicciones realizadas por el modelo y se expresa como un valor porcentual.

### Herramientas Utilizadas :wrench:
- Python 3.9.17
- Bibliotecas de an谩lisis de datos: Pandas, NumPy.
- Bibliotecas de visualizaci贸n: Matplotlib, Seaborn.
- Biblioteca de aprendizaje autom谩tico: scikit-learn.

### Estructura del Proyecto :open_file_folder:
- train.csv: Archivo CSV que contiene los datos de entrenamiento.
- test.csv: Archivo CSV que contiene los datos de validaci贸n.
- titanic.ipynb: Un Jupyter notebook que contiene el c贸digo Python para el an谩lisis de datos.
- funciones.py: Archivo Python que contiene las funciones utilizadas para este proyecto.
- submission.csv: Archivo CSV que contiene las predicciones para el archivo test.csv de acuerdo a las instrucciones proporcionadas por Kaggle.

### C贸mo usar este proyecto :question:
1. Descarga el conjunto de datos desde Kaggle: https://www.kaggle.com/competitions/titanic/data
2. Coloca los archivos CSV descargados (train.csv, test.csv) en la misma carpeta que este proyecto.
3. Abre el Jupyter notebook titanic.ipynb y ejecuta las celdas de c贸digo paso a paso para explorar y analizar los datos.

### Contenido del Jupyter notebook :page_facing_up:
El Jupyter notebook proporciona un an谩lisis completo de los datos, que incluye:
- Exploraci贸n de datos: Resumen estad铆stico, visualizaci贸n de datos, identificaci贸n de valores nulos, etc.
- Preprocesamiento de datos: Limpieza de datos, manejo de valores faltantes, codificaci贸n de variables categ贸ricas, etc.
- An谩lisis de caracter铆sticas: Visualizaci贸n de relaciones entre caracter铆sticas y supervivencia.
- Modelado y predicci贸n: Entrenamiento de modelos de aprendizaje autom谩tico para predecir la supervivencia de los pasajeros.
- Evaluaci贸n del modelo: Evaluaci贸n del accuracy (exactitud) y desempe帽o del modelo.

### Modelos Utilizados :computer:
- Logistic Regression
- K-Nearest Neighbors Classifier
- Decision Tree Classifier
- Random Forest Classifier
- Support Vector Classifier
- Bernoulli Naive Bayes
- Gradient Boosting Classifier
- Voting Classifier

### Resultados :bar_chart:
Se evaluaron todos los modelos utilizando la m茅trica accuracy, y los resultados son los siguientes:

- Logistic Regression: Accuracy: 0.82
- K-Nearest Neighbors Classifier: Accuracy: 0.8
- Decision Tree Classifier: Accuracy: 0.8
- Random Forest Classifier: Accuracy: 0.79
- Support Vector Classifier: Accuracy: 0.83
- Bernoulli NB: Accuracy: 0.8
- Gradient Boosting Classifier: Accuracy: 0.82
- Voting Classifier: Accuracy: 0.84

Para el Voting Classifier se mejor贸 en 1% el puntaje m谩ximo de accuracy obtenido previamente logrando un valor de 0.84.
Se observa que este modelo formado a partir de otros no hace overfitting a los datos ya que las m茅tricas entre train y test son similares.
